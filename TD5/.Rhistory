boston <- Boston
boston <- boston
library(MASS)
boston <- Boston
plot(medv ~ I(lstat^2), data = boston)
plot(medv ~ I(lstat), data = boston)
plot(medv ~ I(lstat^3), data = boston)
plot(medv ~ I(lstat^4), data = boston)
plot(medv ~ I(lstat^5), data = boston)
plot(medv ~ I(lstat^(1/2)), data = boston)
plot(medv ~ I(lstat^(1/3)), data = boston)
plot(medv ~ I(lstat^(1/2)), data = boston)
plot(medv ~ I(lstat^(1/4)), data = boston)
plot(medv ~ I(lstat^(1/2)), data = boston)
plot(medv ~ I(lstat^(1/3)), data = boston)
plot(medv ~ I(lstat^(1/5)), data = boston)
plot(medv ~ I(lstat^(1/3)), data = boston)
plot(medv ~ lstat, data = boston)
plot(medv ~ lstat, data = boston)
plot(medv ~ I(lstat^(1/3)), data = boston)
plot(medv ~ I(lstat^(1/2)), data = boston)
lm(medv ~ lstat + I(lstat^2), data = train.data)
lm(medv ~ lstat + I(lstat^2), data = boston)
plot(medv ~ I(lstat^(1/2)), data = boston)
p_tab <- 0.1:3:0.1
rms_tab <- rep(0, size(p_tab))
p_tab <- 0.1:3:0.1
rms_tab <- rep(0, length(p_tab))
for (p in p_tab){
K <- 10
fold <- sample(1:K, nrow(data.train), replace = TRUE)
rms.val <- rep(0, K)
for (k in K){
lin_reg <- lm(medv ~ lstat + I(lstat^p), data = boston.train, subset = fold != k)
pred <- predict(lin_reg, boston.train[fold != k, ])
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$y)**2))
}
rms_tab[which(p_tab == p)] = mean(rms.val)
}
p_tab <- 0.1:3:0.1
rms_tab <- rep(0, length(p_tab))
for (p in p_tab){
K <- 10
fold <- sample(1:K, nrow(boston.train), replace = TRUE)
rms.val <- rep(0, K)
for (k in K){
lin_reg <- lm(medv ~ lstat + I(lstat^p), data = boston.train, subset = fold != k)
pred <- predict(lin_reg, boston.train[fold != k, ])
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$y)**2))
}
rms_tab[which(p_tab == p)] = mean(rms.val)
}
boston <- Boston
n <- nrow(boston)
p <- ncol(boston) - 1
train <- sample(1:n, round(4*n/5))
boston.train <- boston[train, ]
boston.test <- boston[-train, ]
p_tab <- 0.1:3:0.1
rms_tab <- rep(0, length(p_tab))
for (p in p_tab){
K <- 10
fold <- sample(1:K, nrow(boston.train), replace = TRUE)
rms.val <- rep(0, K)
for (k in K){
lin_reg <- lm(medv ~ lstat + I(lstat^p), data = boston.train, subset = fold != k)
pred <- predict(lin_reg, boston.train[fold != k, ])
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$y)**2))
}
rms_tab[which(p_tab == p)] = mean(rms.val)
}
plot(rms ~ p_tab)
plot(rms_tab ~ p_tab)
rms_tab
p_tab <- 0.1:3:0.1
rms_tab <- c()
for (p in p_tab){
K <- 10
fold <- sample(1:K, nrow(boston.train), replace = TRUE)
rms.val <- rep(0, K)
for (k in K){
lin_reg <- lm(medv ~ lstat + I(lstat^p), data = boston.train, subset = fold != k)
pred <- predict(lin_reg, boston.train[fold != k, ])
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$y)**2))
}
rms_tab = c(rms_tab, mean(rms.val))
}
rms_tab
p
plot(medv ~ I(lstat^(1/2)), data = boston)
plot(medv ~ lstat, data = boston)
boston <- Boston
nb_data_boston <- nrow(boston)
nb_pred_boston <- ncol(boston) - 1
train <- sample(1:n, round(4*n/5))
boston.train <- boston[train, ]
boston.test <- boston[-train, ]
p_tab <- 0.1:3:0.1
rms_tab <- c()
for (p in p_tab){
K <- 10
fold <- sample(1:K, nrow(boston.train), replace = TRUE)
rms.val <- rep(0, K)
for (k in K){
lin_reg <- lm(medv ~ lstat + I(lstat^p), data = boston.train, subset = fold != k)
pred <- predict(lin_reg, boston.train[fold != k, ])
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$y)**2))
}
rms_tab = c(rms_tab, mean(rms.val))
}
plot(rms_tab ~ p_tab)
p_tab <- 0.1:3:0.1
rms_tab <- c()
for (p in p_tab){
K <- 10
fold <- sample(1:K, nrow(boston.train), replace = TRUE)
rms.val <- rep(0, K)
for (k in K){
lin_reg <- lm(medv ~ lstat + I(lstat^p), data = boston.train, subset = fold != k)
pred <- predict(lin_reg, boston.train[fold != k, ])
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$y)**2))
}
rms_tab = c(rms_tab, mean(rms.val))
print(rms_tab)
}
nb_pred_boston
p_tab
p_tab <- seq(0.1,3,0.1)
p_tab
p_tab <- seq(0.1,3,0.1)
rms_tab <- rep(0, length(p_tab))
for (p in p_tab){
K <- 10
fold <- sample(1:K, nrow(boston.train), replace = TRUE)
rms.val <- rep(0, K)
for (k in K){
lin_reg <- lm(medv ~ lstat + I(lstat^p), data = boston.train, subset = fold != k)
pred <- predict(lin_reg, boston.train[fold != k, ])
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$y)**2))
}
rms_tab[which(p_tab == p)] = mean(rms.val)
}
plot(rms_tab ~ p_tab)
rms_tab
boston.train
p_tab <- seq(0.1,3,0.1)
rms_tab <- rep(0, length(p_tab))
for (p in p_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)
rms.val <- rep(0, K)
for (k in K){
lin_reg <- lm(medv ~ lstat + I(lstat^p), data = boston.train, subset = fold != k)
pred <- predict(lin_reg, boston.train[fold != k, ])
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$y)**2))
}
rms_tab[which(p_tab == p)] = mean(rms.val)
}
p_tab <- seq(0.1,3,0.1)
rms_tab <- rep(0, length(p_tab))
for (p in p_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)
rms.val <- rep(0, K)
for (k in K){
lin_reg <- lm(medv ~ lstat + I(lstat^p), data = boston.train, subset = fold != k)
pred <- predict(lin_reg, boston.train[fold == k, ])
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$y)**2))
}
rms_tab[which(p_tab == p)] = mean(rms.val)
}
boston.train[fold == 1, ]
plot(medv ~ poly(lstat^(5)), data = boston)
plot(medv ~ poly(lstat^5), data = boston)
p_tab <- seq(1, 10, 1)
rms_tab <- rep(0, length(p_tab))
for (p in p_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)
rms.val <- rep(0, K)
for (k in K){
lin_reg <- lm(medv ~ poly(lstat, p), data = boston.train, subset = fold != k)
pred <- predict(lin_reg, boston.train[fold == k, ])
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$y)**2))
}
rms_tab[which(p_tab == p)] = mean(rms.val)
}
plot(rms_tab ~ p_tab)
rms_tab
p_tab <- seq(1, 10, 1)
rms_tab <- rep(0, length(p_tab))
for (p in p_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)
rms.val <- rep(0, K)
for (k in K){
lin_reg <- lm(medv ~ poly(lstat, p), data = boston.train, subset = fold != k)
pred <- predict(lin_reg, boston.train[fold == k, ])
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$y)**2))
}
print(mean(rms.val))
rms_tab[which(p_tab == p)] = mean(rms.val)
}
p_tab <- seq(1, 10, 1)
rms_tab <- rep(0, length(p_tab))
for (p in p_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)
rms.val <- rep(0, K)
for (k in 1:K){
lin_reg <- lm(medv ~ poly(lstat, p), data = boston.train, subset = fold != k)
pred <- predict(lin_reg, boston.train[fold == k, ])
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$y)**2))
}
rms_tab[which(p_tab == p)] = mean(rms.val)
}
plot(rms_tab ~ p_tab)
rms_tab
p_tab <- seq(1, 10, 1)  # Tableau des degrés du polynôme
rms_tab <- rep(0, length(p_tab))  # Tableau des résultats RMS
for (p in p_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)  # Création des folds
rms.val <- rep(0, K)  # Stocker les valeurs RMS pour chaque fold
for (k in 1:K){  # Correction de la boucle
# Modèle de régression polynomiale
lin_reg <- lm(medv ~ poly(lstat, p), data = boston.train, subset = fold != k)
# Prédictions sur les données du fold k
pred <- predict(lin_reg, boston.train[fold == k, ])
# Calcul du RMS pour le fold k
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$medv)^2))
}
# Calcul de la moyenne des RMS sur les K folds
rms_tab[which(p_tab == p)] <- mean(rms.val)
}
plot(rms_tab ~ p_tab)
plot(rms_tab ~ p_tab, mean = "Erreur de validation en fonction du degré du polynôme", xlab = "Degré", ylab = "RMSE")
plot(rms_tab ~ p_tab, main = "Erreur de validation en fonction du degré du polynôme", xlab = "Degré", ylab = "RMSE")
p_tab <- seq(1, 10, 1)  # Tableau des degrés du polynôme
rms_tab <- rep(0, length(p_tab))  # Tableau des résultats RMS
for (p in p_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)  # Création des folds
rms.val <- rep(0, K)  # Stocker les valeurs RMS pour chaque fold
for (k in 1:K){  # Correction de la boucle
# Modèle de régression polynomiale
lin_reg <- lm(medv ~ poly(lstat, p), data = boston.train, subset = fold != k)
# Prédictions sur les données du fold k
pred <- predict(lin_reg, boston.train[fold == k, ])
# Calcul du RMS pour le fold k
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$medv)^2))
}
# Calcul de la moyenne des RMS sur les K folds
rms_tab[which(p_tab == p)] <- mean(rms.val)
}
plot(rms_tab ~ p_tab, main = "Erreur de validation en fonction du degré du polynôme", xlab = "Degré", ylab = "RMSE")
print("Le degré qui minimise le RMSE est : ", rms_tab[which.min(rms_tab)])
rms_tab
rms_tab[which.min(rms_tab)]
print("Le degré qui minimise le RMSE est : %d", rms_tab[which.min(rms_tab)])
print("Le degré qui minimise le RMSE est : ", rms_tab[which.min(rms_tab)])
print("Le degré qui minimise le RMSE est : ", p_tab[which.min(rms_tab)])
print("Le degré qui minimise le RMSE est : ", p_tab[which.min(rms_tab)])
p_tab <- seq(1, 10, 1)  # Tableau des degrés du polynôme
rms_tab <- rep(0, length(p_tab))  # Tableau des résultats RMS
for (p in p_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)  # Création des folds
rms.val <- rep(0, K)  # Stocker les valeurs RMS pour chaque fold
for (k in 1:K){  # Correction de la boucle
# Modèle de régression polynomiale
lin_reg <- lm(medv ~ poly(lstat, p), data = boston.train, subset = fold != k)
# Prédictions sur les données du fold k
pred <- predict(lin_reg, boston.train[fold == k, ])
# Calcul du RMS pour le fold k
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$medv)^2))
}
# Calcul de la moyenne des RMS sur les K folds
rms_tab[which(p_tab == p)] <- mean(rms.val)
}
print("Le degré qui minimise le RMSE est : ", p_tab[which.min(rms_tab)]
print("Le degré qui minimise le RMSE est : ", p_tab[which.min(rms_tab)])
printf
printf("Le degré qui minimise le RMSE est : ", p_tab[which.min(rms_tab)])
library(MASS)
boston <- Boston
nb_data_boston <- nrow(boston)
nb_pred_boston <- ncol(boston) - 1
train <- sample(1:n, round(4*n/5))
boston.train <- boston[train, ]
boston.test <- boston[-train, ]
plot(medv ~ lstat, data = boston)
plot(medv ~ poly(lstat^5), data = boston)
p_tab <- seq(1, 10, 1)  # Tableau des degrés du polynôme
rms_tab <- rep(0, length(p_tab))  # Tableau des résultats RMS
for (p in p_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)  # Création des folds
rms.val <- rep(0, K)  # Stocker les valeurs RMS pour chaque fold
for (k in 1:K){  # Correction de la boucle
# Modèle de régression polynomiale
lin_reg <- lm(medv ~ poly(lstat, p), data = boston.train, subset = fold != k)
# Prédictions sur les données du fold k
pred <- predict(lin_reg, boston.train[fold == k, ])
# Calcul du RMS pour le fold k
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$medv)^2))
}
# Calcul de la moyenne des RMS sur les K folds
rms_tab[which(p_tab == p)] <- mean(rms.val)
}
plot(rms_tab ~ p_tab, main = "Erreur de validation en fonction du degré du polynôme", xlab = "Degré", ylab = "RMSE")
print("Le degré qui minimise le RMSE est : ", p_tab[which.min(rms_tab)])
p_tab[which.min(rms_tab)]
print("Le degré qui minimise le RMSE est : ", p_tab[which.min(rms_tab)])
print(paste("Le degré qui minimise le RMSE est : ", p_tab[which.min(rms_tab)]))
library(splines)
ns(boston, df = 4)
ns(boston$lstat, df = 4)
plot(medv ~ ns(boston$lstat, df = 4), data = boston)
plot(medv ~ ns(lstat, df = 4), data = boston)
plot(ns(lstat, df = 4), data = boston)
plot(ns(boston$lstat, df = 4), data = boston.train)
plot(ns(boston$lstat, df = 2), data = boston.train)
df_tab <- seq(1, 10, 1)
rms_tab <- rep(0, length(p_tab))
for (df in df_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)  # Création des folds
rms.val <- rep(0, K)
for (k in 1:K){
# Modèle de régression polynomiale
lin_reg <- lm(medv ~ ns(boston$lstat, df = df), data = boston.train, subset = fold != k)
# Prédictions sur les données du fold k
pred <- predict(lin_reg, boston.train[fold == k, ])
# Calcul du RMS pour le fold k
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$medv)^2))
}
# Calcul de la moyenne des RMS sur les K folds
rms_tab[which(df_tab == df)] <- mean(rms.val)
}
for (df in df_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)  # Création des folds
rms.val <- rep(0, K)
for (k in 1:K){
# Modèle de régression polynomiale
lin_reg <- lm(medv ~ ns(boston.train$lstat, df = df), data = boston.train, subset = fold != k)
# Prédictions sur les données du fold k
pred <- predict(lin_reg, boston.train[fold == k, ])
# Calcul du RMS pour le fold k
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$medv)^2))
}
# Calcul de la moyenne des RMS sur les K folds
rms_tab[which(df_tab == df)] <- mean(rms.val)
}
plot(rms_tab ~ df_tab, main = "Erreur de validation en fonction du degré du polynôme", xlab = "Degré", ylab = "RMSE")
print(paste("Le degré qui minimise le RMSE est : ", df_tab[which.min(rms_tab)]))
df_tab <- seq(1, 10, 1)
rms_tab <- rep(0, length(p_tab))
for (df in df_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)  # Création des folds
rms.val <- rep(0, K)
for (k in 1:K){
# Modèle de régression polynomiale
lin_reg <- lm(medv ~ ns(boston.train$lstat, df = df), data = boston.train, subset = fold != k)
# Prédictions sur les données du fold k
pred <- predict(lin_reg, boston.train[fold == k, ])
# Calcul du RMS pour le fold k
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$medv)^2))
}
# Calcul de la moyenne des RMS sur les K folds
rms_tab[which(df_tab == df)] <- mean(rms.val)
}
plot(rms_tab ~ df_tab, main = "Erreur de validation en fonction du degré du polynôme", xlab = "Degré", ylab = "RMSE")
print(paste("Le degré qui minimise le RMSE est : ", df_tab[which.min(rms_tab)]))
fit<-lm(medv ~ bs(lstat,df=1),data=boston.train)
ypred<-predict(fit,newdata=boston.test,interval="c")
plot(boston$lstat, boston$medv,cex=0.5,xlab="lstat",ylab="medv")
fit <- lm(medv ~ bs(lstat, df = 1), data = boston.train)
# Prédictions sur les données de test avec intervalle de confiance
ypred <- predict(fit, newdata = boston.test, interval = "confidence")
# Affichage du graphique : scatter plot des données originales et courbe de prédiction
plot(boston.test$lstat, boston.test$medv, cex = 0.5, xlab = "lstat", ylab = "medv", main = "Prédiction avec spline")
lines(boston.test$lstat, ypred[, "fit"], col = "red")
lines(boston.test$lstat, ypred[, "lwr"], col = "blue", lty = 2)
lines(boston.test$lstat, ypred[, "upr"], col = "blue", lty = 2)
plot(boston.test$lstat, boston.test$medv, cex = 0.5, xlab = "lstat", ylab = "medv", main = "Prédiction avec spline")
lines(boston.test$lstat, ypred[, "fit"], col = "red")
plot(boston.test$lstat, boston.test$medv, cex = 0.5, xlab = "lstat", ylab = "medv", main = "Prédiction avec spline")
lines(boston.test$lstat[idx$ix], ypred[idx=ix, "fit"], col = "red")
ypred
ord <- order(boston.test$lstat)
plot(boston.test$lstat, boston.test$medv, cex = 0.5, xlab = "lstat", ylab = "medv", main = "Prédiction avec spline")
lines(boston.test$lstat[ord], ypred[ord, "fit"], col = "red")  # Courbe de prédiction triée
lines(boston.test$lstat[ord], ypred[ord, "lwr"], col = "blue", lty = 2)  # Borne inférieure triée
lines(boston.test$lstat[ord], ypred[ord, "upr"], col = "blue", lty = 2)  # Borne supérieure triée
ss <- smooth.spline(x = boston.train$lstat, y = boston.train$medv, cv = TRUE)
ss <- smooth.spline(x = boston.train$lstat, y = boston.train$medv)
ss
print(paste("Degré de liberté : "), ss$df)
print(paste("Degré de liberté : ", ss$df))
lines(boston.train$lstat, ss$y, col = "blue", lwd = 2)
ss <- smooth.spline(x = boston.train$lstat, y = boston.train$medv)
print(paste("Degré de liberté : ", ss$df))
plot(boston.train$lstat, boston.train$medv)
lines(boston.train$lstat, ss$y, col = "blue", lwd = 2)
size(ss)
boston.train$lstat
ss$y
lines(ss$x, ss$y, col = "blue", lwd = 2)
p_tab <- seq(1, 10, 1)  # Tableau des degrés du polynôme
rms_tab <- rep(0, length(p_tab))  # Tableau des résultats RMS
for (p in p_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)  # Création des folds
rms.val <- rep(0, K)  # Stocker les valeurs RMS pour chaque fold
for (k in 1:K){  # Correction de la boucle
# Modèle de régression polynomiale
lin_reg <- lm(medv ~ poly(lstat, p), data = boston.train, subset = fold != k)
# Prédictions sur les données du fold k
pred <- predict(lin_reg, boston.train[fold == k, ])
# Calcul du RMS pour le fold k
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$medv)^2))
}
# Calcul de la moyenne des RMS sur les K folds
rms_tab[which(p_tab == p)] <- mean(rms.val)
}
plot(rms_tab ~ p_tab, main = "Erreur de validation en fonction du degré du polynôme", xlab = "Degré", ylab = "RMSE")
print(paste("Le degré qui minimise le RMSE est : ", p_tab[which.min(rms_tab)]))
fit <- lm(medv ~ poly(lstat, p_tab[which.min(rms_tab)]), data = boston.train)
ypred <- predict(fit, newdata = boston.test, interval = "confidence")
ord <- order(boston.test$lstat)
plot(boston.test$lstat, boston.test$medv, cex = 0.5, xlab = "lstat", ylab = "medv", main = "Prédiction avec spline")
plot(boston.test$lstat, boston.test$medv, cex = 0.5, xlab = "lstat", ylab = "medv", main = "Prédiction avec spline")
lines(boston.test$lstat[ord], ypred[ord, "fit"], col = "red")
lines(boston.test$lstat[ord], ypred[ord, "lwr"], col = "blue", lty = 2)
lines(boston.test$lstat[ord], ypred[ord, "upr"], col = "blue", lty = 2)
plot(rms_tab ~ p_tab, main = "Erreur de validation en fonction du degré du polynôme", xlab = "Degré", ylab = "RMSE")
print(paste("Le degré qui minimise le RMSE est : ", p_tab[which.min(rms_tab)]))
fit <- lm(medv ~ poly(lstat, p_tab[which.min(rms_tab)]), data = boston.train)
ypred_poly <- predict(fit, newdata = boston.test, interval = "confidence")
ord <- order(boston.test$lstat)
plot(boston.test$lstat, boston.test$medv, cex = 0.5, xlab = "lstat", ylab = "medv", main = "Prédiction avec spline")
lines(boston.test$lstat[ord], ypred_poly[ord, "fit"], col = "red")
lines(boston.test$lstat[ord], ypred_poly[ord, "lwr"], col = "blue", lty = 2)
lines(boston.test$lstat[ord], ypred_poly[ord, "upr"], col = "blue", lty = 2)
df_tab <- seq(1, 10, 1)
rms_tab <- rep(0, length(p_tab))
for (df in df_tab){
K <- 5
fold <- sample(1:K, nrow(boston.train), replace = TRUE)  # Création des folds
rms.val <- rep(0, K)
for (k in 1:K){
# Modèle de régression polynomiale
lin_reg <- lm(medv ~ ns(boston.train$lstat, df = df), data = boston.train, subset = fold != k)
# Prédictions sur les données du fold k
pred <- predict(lin_reg, boston.train[fold == k, ])
# Calcul du RMS pour le fold k
rms.val[k] <- sqrt(mean((pred - boston.train[fold == k, ]$medv)^2))
}
# Calcul de la moyenne des RMS sur les K folds
rms_tab[which(df_tab == df)] <- mean(rms.val)
}
plot(rms_tab ~ df_tab, main = "Erreur de validation en fonction du degré du polynôme", xlab = "Degré", ylab = "RMSE")
print(paste("Le degré qui minimise le RMSE est : ", df_tab[which.min(rms_tab)]))
fit <- lm(medv ~ bs(lstat, df = 1), data = boston.train)
ypred_ns <- predict(fit, newdata = boston.test, interval = "confidence")
ord <- order(boston.test$lstat)
plot(boston.test$lstat, boston.test$medv, cex = 0.5, xlab = "lstat", ylab = "medv", main = "Prédiction avec spline")
lines(boston.test$lstat[ord], ypred_ns[ord, "fit"], col = "red")
lines(boston.test$lstat[ord], ypred_ns[ord, "lwr"], col = "blue", lty = 2)
lines(boston.test$lstat[ord], ypred_ns[ord, "upr"], col = "blue", lty = 2)
plot(medv ~ lstat, data = boston)
lines(boston.test$lstat[ord], ypred_poly[ord, "fit"], col = "red")
lines(boston.test$lstat[ord], ypred_ns[ord, "fit"], col = "green")
lines(ss$x, ss$y, col = "blue", lwd = 2)
legend("topright", legend = c("Polynomial", "Natural splines", "Smooth splines"), col = c("blue", "green", "red"), lty = 1)
plot(medv ~ lstat, data = boston)
lines(boston.test$lstat[ord], ypred_poly[ord, "fit"], col = "red")
lines(boston.test$lstat[ord], ypred_ns[ord, "fit"], col = "green")
lines(ss$x, ss$y, col = "blue")
legend("topright", legend = c("Polynomial", "Natural splines", "Smooth splines"), col = c("blue", "green", "red"), lty = 1)
plot(medv ~ lstat, data = boston, main = "Regressino functions")
lines(boston.test$lstat[ord], ypred_poly[ord, "fit"], col = "red")
lines(boston.test$lstat[ord], ypred_ns[ord, "fit"], col = "green")
lines(ss$x, ss$y, col = "blue")
legend("topright", legend = c("Polynomial", "Natural splines", "Smooth splines"), col = c("blue", "green", "red"), lty = 1)
