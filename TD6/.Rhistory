library(farff)
library(dplyr)
library(corrplot)
# Lecture du dataset
setwd("C:/Users/antoi/Desktop/UTC/GI05/SY19/Projet")
bank_marketing <- readARFF("bank_marketing.arff")
numeric_columns <- sapply(bank_marketing, is.numeric)
numeric_data <- bank_marketing[, numeric_columns]
cor_matrix <- cor(numeric_data, use = "complete.obs")
corrplot(cor_matrix, method = "color", type = "upper",
tl.col = "black", tl.srt = 45,
addCoef.col = "black",
number.cex = 0.7)
expenditure_default <- read.csv("data.csv", sep = ",")
setwd("C:/Users/antoi/Desktop/UTC/GI05/SY19/TD7")
expenditure_default <- read.csv("data.csv", sep = ",")
expenditure_default
expenditure_default.train <- expenditure_default[1:10000, ]
expenditure_default.test <- expenditure_default[10000:, ]
expenditure_default.test <- expenditure_default[10000: , ]
n = nrow(expenditure_default)
p = ncol(expenditure_default) - 1
expenditure_default.test <- expenditure_default[10000: n, ]
expenditure_default.test <- expenditure_default[10001: n, ]
library(rpart)
library(rpart.plot)
tree_model <- rpart(Cardhldr~. -Default -Exp_Inc -Spending -Logspend, data = expenditure_default.train, method = "class", parms = list(split = 'gini'))
tree_model <- rpart(CARDHLDR~. -DEFAULT -EXP_INC -SPENDING -LOGSPEND, data = expenditure_default.train, method = "class", parms = list(split = 'gini'))
rpart.plot(tree_model, box.palette="RdBu", shadow.col="gray",
fallen.leaves=FALSE)
plotcp(tree_model)
tree_model.pred <- predict(tree_model, newdata = expenditure_default.test)
tree_model.pred <- predict(tree_model, newdata = expenditure_default.test)
tree_model.conf_mat <- table(tree_model.pred, expenditure_default.test$CARDHLDR)
tree_model.pred
tree_model.conf_mat <- table(tree_model.pred$class, expenditure_default.test$CARDHLDR)
tree_model.pred <- predict(tree_model, newdata = expenditure_default.test, response = "class")
tree_model.pred
tree_model.conf_mat <- table(tree_model.pred$class, expenditure_default.test$CARDHLDR)
tree_model.pred <- predict(tree_model, newdata = expenditure_default.test)
tree_model.pred
tree_model.pred <- predict(tree_model, newdata = expenditure_default.test, type = "class")
tree_model.conf_mat <- table(tree_model.pred$class, expenditure_default.test$CARDHLDR)
tree_model.pred
train_index <- sample(1:nrow(expenditure_default), 10000)
expenditure_default.train <- expenditure_default[train_index, ]
expenditure_default.test <- expenditure_default[-train_index, ]
tree_model <- rpart(CARDHLDR~. -DEFAULT -EXP_INC -SPENDING -LOGSPEND, data = expenditure_default.train, method = "class", parms = list(split = 'gini'))
rpart.plot(tree_model, box.palette="RdBu", shadow.col="gray",
fallen.leaves=FALSE)
plotcp(tree_model)
tree_model.pred <- predict(tree_model, newdata = expenditure_default.test, type = "class")
tree_model.conf_mat <- table(tree_model.pred, expenditure_default.test$CARDHLDR)
print(tree_model.conf_mat)
error_rate <- mean(tree_model.pred != expenditure_default.test$CARDHLDR)
print(error_rate)
rpart.plot(tree_model, box.palette="RdBu", shadow.col="gray",
fallen.leaves=FALSE)
tree_model <- rpart(CARDHLDR ~ . -DEFAULT -EXP_INC -SPENDING -LOGSPEND, data = expenditure_default.train, method = "class")
rpart.plot(tree_model, box.palette="RdBu", shadow.col="gray",
fallen.leaves=FALSE)
printcp(tree_model)
tree_model.pred <- predict(tree_model, newdata = expenditure_default.test, type = "class")
tree_model.conf_mat <- table(tree_model.pred, expenditure_default.test$CARDHLDR)
print(tree_model.conf_mat)
error_rate <- mean(tree_model.pred != expenditure_default.test$CARDHLDR)
print(error_rate)
printcp(tree_model)
optimal_cp <- tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"]
pruned_tree <- prune(tree_model, cp = optimal_cp)
rpart.plot(pruned_tree)
library(pROC)
tree_model.pred_prob <- predict(tree_model, newdata = expenditure_default.test, type = "prob")
tree_model.pred_prob
tree_model.pred_prob <- predict(tree_model, newdata = expenditure_default.test, type = "prob")[, 2]
tree_model.roc <- roc(expenditure_default.test$CARDHLDR, tree_model.pred_prob)
print(tree_model.roc)
plot(tree_model.roc)
library(randomForest)
print(rf_model)
rf_model <- randomForest(x = expenditure_default.train[, !names(expenditure_default.train) %in% "CARDHLDR"],
y = expenditure_default.train[, names(expenditure_default.train) %in% "CARDHLDR"],
xtest = expenditure_default.test[, !names(expenditure_default.train) %in% "CARDHLDR"],
ytest = expenditure_default.test[, names(expenditure_default.train) %in% "CARDHLDR"],
ntree = 500,
mtry = floor(sqrt(expenditure_default.train)),
nodesize = 1,
importance = TRUE,
keep.forest = TRUE)
rf_model <- randomForest(x = expenditure_default.train[, !names(expenditure_default.train) %in% "CARDHLDR"],
y = expenditure_default.train[, names(expenditure_default.train) %in% "CARDHLDR"],
xtest = expenditure_default.test[, !names(expenditure_default.train) %in% "CARDHLDR"],
ytest = expenditure_default.test[, names(expenditure_default.train) %in% "CARDHLDR"],
ntree = 500,
nodesize = 1,
importance = TRUE,
keep.forest = TRUE)
x.train = expenditure_default.train[, c("AGE", "ADEPCNT", "ACADMOS", "MAJORDGR")]
x.train = expenditure_default.train[, c("AGE", "ADEPCNT", "ACADMOS", "MAJORDRG")]
y.train = expenditure_default.train$CARDHLDR
x.test = expenditure_default.test[, c("AGE", "ADEPCNT", "ACADMOS", "MAJORDRG")]
y.test = expenditure_default.test$CARDHLDR
rf_model <- randomForest(x = x.train,
y = y.train,
xtest = x.test,
ytest = y.test,
ntree = 500,
nodesize = 1,
importance = TRUE,
keep.forest = TRUE)
print(rf_model)
x.train = expenditure_default.train[, c("AGE", "ADEPCNT", "ACADMOS", "MAJORDRG")]
y.train = as.factor(expenditure_default.train$CARDHLDR)
x.test = expenditure_default.test[, c("AGE", "ADEPCNT", "ACADMOS", "MAJORDRG")]
y.test = as.factor(expenditure_default.test$CARDHLDR)
library(randomForest)
rf_model <- randomForest(x = x.train,
y = y.train,
xtest = x.test,
ytest = y.test,
ntree = 50,
nodesize = 1,
importance = TRUE,
keep.forest = TRUE)
print(rf_model)
rf.confusion_matrix <- table(Predicted = rf_model$test$predicted, Actual = y.test)
print(rf.confusion_matrix)
rf.accuracy.test <- sum(rf_model$test$predicted == y.test) / length(y.test)
print(rf.accuracy.test)
rf.error_rate <- mean(rf_model$test$predicted != y.test)
print(rf.error_rate)
varImpPlot(rf_model)
varImpPlot(rf_model)
reg_log <- glm(CARDHLDR ~ . -DEFAULT -EXP_INC -SPENDING -LOGSPEND, data = expenditure_default.train, family = "binomial")
reg_log.pred <- predict(reg_log, newdata = expenditure_default.test)
reg_log.pred
reg_log <- glm(CARDHLDR ~ ., data = expenditure_default.train, family = "binomial")
tree_model <- rpart(CARDHLDR ~ ., data = expenditure_default.train, method = "class")
rpart.plot(tree_model, box.palette="RdBu", shadow.col="gray",
fallen.leaves=FALSE)
plotcp(tree_model)
tree_model.pred_class <- predict(tree_model, newdata = expenditure_default.test, type = "class")
tree_model.pred_prob <- predict(tree_model, newdata = expenditure_default.test, type = "prob")[, 2]
tree_model.conf_mat <- table(tree_model.pred_class, expenditure_default.test$CARDHLDR)
print(tree_model.conf_mat)
error_rate <- mean(tree_model.pred_class != expenditure_default.test$CARDHLDR)
print(error_rate)
printcp(tree_model)
optimal_cp <- tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"]
pruned_tree <- prune(tree_model, cp = optimal_cp)
rpart.plot(pruned_tree)
tree_model.roc <- roc(expenditure_default.test$CARDHLDR, tree_model.pred_prob)
print(tree_model.roc)
plot(tree_model.roc)
x.train = expenditure_default.train[, setdiff(names(expenditure_default.train), "Cardhldr")]
y.train = as.factor(expenditure_default.train$CARDHLDR)
x.test = expenditure_default.test[, setdiff(names(expenditure_default.train), "Cardhldr")]
y.test = as.factor(expenditure_default.test$CARDHLDR)
library(randomForest)
rf_model <- randomForest(x = x.train,
y = y.train,
xtest = x.test,
ytest = y.test,
ntree = 50,
nodesize = 1,
importance = TRUE,
keep.forest = TRUE)
expenditure_default <- expenditure_default[, -c(2,12:14)]
train_index <- sample(1:nrow(expenditure_default), 10000)
expenditure_default.train <- expenditure_default[train_index, ]
expenditure_default.test <- expenditure_default[-train_index, ]
tree_model <- rpart(CARDHLDR ~ ., data = expenditure_default.train, method = "class")
rpart.plot(tree_model, box.palette="RdBu", shadow.col="gray",
fallen.leaves=FALSE)
plotcp(tree_model)
tree_model.pred_class <- predict(tree_model, newdata = expenditure_default.test, type = "class")
tree_model.pred_prob <- predict(tree_model, newdata = expenditure_default.test, type = "prob")[, 2]
tree_model.conf_mat <- table(tree_model.pred_class, expenditure_default.test$CARDHLDR)
print(tree_model.conf_mat)
error_rate <- mean(tree_model.pred_class != expenditure_default.test$CARDHLDR)
print(error_rate)
printcp(tree_model)
optimal_cp <- tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"]
pruned_tree <- prune(tree_model, cp = optimal_cp)
rpart.plot(pruned_tree)
tree_model.roc <- roc(expenditure_default.test$CARDHLDR, tree_model.pred_prob)
print(tree_model.roc)
plot(tree_model.roc)
x.train = expenditure_default.train[, setdiff(names(expenditure_default.train), "CARDHLDR")]
y.train = as.factor(expenditure_default.train$CARDHLDR)
x.test = expenditure_default.test[, setdiff(names(expenditure_default.train), "CARDHLDR")]
y.test = as.factor(expenditure_default.test$CARDHLDR)
library(randomForest)
rf_model <- randomForest(x = x.train,
y = y.train,
xtest = x.test,
ytest = y.test,
ntree = 50,
nodesize = 1,
importance = TRUE,
keep.forest = TRUE)
print(rf_model)
rf.confusion_matrix <- table(Predicted = rf_model$test$predicted, Actual = y.test)
print(rf.confusion_matrix)
rf.error_rate <- mean(rf_model$test$predicted != y.test)
print(rf.error_rate)
varImpPlot(rf_model)
reg_log <- glm(CARDHLDR ~ ., data = expenditure_default.train, family = "binomial")
reg_log.pred <- predict(reg_log, newdata = expenditure_default.test)
reg_log.pred
rf.error_rate <- mean(rf_model$test$predicted != y.test, response = "class")
reg_log.pred <- predict(reg_log, newdata = expenditure_default.test, response = "class")
reg_log.pred
reg_log.pred <- predict(reg_log, newdata = expenditure_default.test, type = "class")
reg_log <- glm(CARDHLDR ~ ., data = expenditure_default.train, family = "binomial")
reg_log.pred_proba <- predict(reg_log, expenditure_default.test, type = "response")
reg_log.pred <- ifelse(pred_proba > 0.5, 1, 0)
reg_log.pred <- ifelse(reg_log.pred_proba > 0.5, 1, 0)
reg_log.error_rate <- mean(reg_log.pred != expenditure_default.test$CARDHLDR)
print(reg_log.error_rate)
library(MASS)
data(Boston)
Boston
train_index <- sample(1:nrow(Boston), 4 * nrow(Boston) / 5)
boston.train <- Boston[train_index, ]
boston.test <- Boston[-train_index, ]
tree_model_2 <- rpart(medv ~., data = Boston, subset = train)
tree_model_2 <- rpart(medv ~., data = Boston, subset = train_index)
rpart.plot(tree_model_2, box.palette="RdBu", shadow.col="gray",
fallen.leaves=FALSE)
tree_model_2 <- rpart(medv ~., data = Boston, subset = train_index)
rpart.plot(tree_model_2, box.palette="RdBu", shadow.col="gray",
fallen.leaves=FALSE)
plotcp(tree_model_2)
tree_model_2.pred_class <- predict(tree_model_2, newdata = boston.test, type = "class")
tree_model_2.pred <- predict(tree_model_2, newdata = boston.test)
tree_model_2.pred
tree_model_2.rmse <- sqrt(mean((tree_model_2.pred - boston.test$medv)**2))
tree_model_2.rmse
rf_model <- randomForest(x = boston.train[, setdiff(names(boston.train), "medv")],
y = boston.train$medv,
xtest = boston.test[, setdiff(names(boston.test), "medv")],
ytest = boston.test$medv,
ntree = 50,
nodesize = 1,
importance = TRUE,
keep.forest = TRUE)
rf_model.rmse <- sqrt(mean((rf_model$test$predicted - boston.test$medv)**2))
print(rf_model.error_rate)
rf_model.rmse <- sqrt(mean((rf_model$test$predicted - boston.test$medv)**2))
print(rf_model.rmse)
varImpPlot(rf_model)
varImpPlot(rf_model)
